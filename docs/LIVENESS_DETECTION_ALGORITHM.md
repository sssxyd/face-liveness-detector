# 活体检测算法（Liveness Detection Algorithm）

## 目录

1. [概述](#概述)
2. [核心原理](#核心原理)
3. [检测策略](#检测策略)
4. [正向检测](#正向检测)
5. [逆向检测](#逆向检测)
6. [综合决策](#综合决策)
7. [性能指标](#性能指标)
8. [常见问题](#常见问题)

---

## 概述

本活体检测器采用**双重检测策略**，同时进行**正向检测**（检测真人生物特征）和**逆向检测**（检测照片几何约束），以高置信度区分真实人脸和手持照片。

### 关键特点

- ✅ **高灵敏度**：能检测极微妙的生物特征变化
- ✅ **鲁棒性强**：对照片倾转、旋转等攻击有防护
- ✅ **物理约束检测**：利用几何学和射影定理
- ✅ **实时性**：单帧 ~100ms（基于 MediaPipe）

### 应用场景

| 场景 | 描述 |
|-----|------|
| 人脸识别 | 防止用照片欺骗人脸识别系统 |
| 身份验证 | 在线身份核验 |
| 移动支付 | 防止盗刷 |
| 账户登录 | 防止账户被冒用 |

---

## 核心原理

### 问题定义

给定视频序列 $\{I_1, I_2, ..., I_N\}$，判定是否为：
- **活体（Live）**：真实的人脸直播
- **欺骗（Spoofed）**：照片、视频回放、3D面具等

### 关键观察

| 特性 | 真人活体 | 照片/视频 |
|-----|--------|----------|
| **眨眼周期** | 自然周期 100-400ms | 无法产生 |
| **眼睛对称性** | 双眼同步眨眼 | 无法同步 |
| **3D深度分布** | 鼻子凸出，眼窝凹陷 | 平面（Z坐标恒定） |
| **单应性约束** | 头部旋转时不满足 | 平面旋转完全满足 |
| **交叉比率** | 头部旋转时变化 | 平面旋转保持不变 |
| **运动-形变相关** | 高度相关 | 零相关 |

### ⚠️ 关键理解：Z 坐标的局限性

MediaPipe 返回的 Z 坐标**不是真实的物理深度**，而是神经网络从 2D 图像推断的**相对深度**：

```
摄像头 (2D RGB) → MediaPipe 神经网络 → 推断的 Z 坐标
```

- **对真人**：推断结果接近真实的 3D 结构
- **对高分辨率照片**：也可能推断出"假"的 3D 结构（因为照片上的人脸也有阴影、透视感）

**因此，Z 坐标分析只能作为辅助参考，不能作为主要判据！**

---

## 检测策略

### 整体架构

```
视频帧序列
    ↓
┌─────────────────────────────────┐
│  MediaPipe Face Mesh            │ (468 个 3D 关键点)
│  + 坐标归一化                   │
└─────────────────┬───────────────┘
                  ↓
    ┌─────────────┴──────────────┐
    ↓                            ↓
┌─────────────────┐    ┌──────────────────┐
│  正向检测       │    │  逆向检测        │
│  (生物特征)     │    │  (几何约束)      │
└────────┬────────┘    └────────┬─────────┘
         │                      │
         │    ┌─────────────────┘
         │    ↓
         │  综合评分
         │  ├─ 正向得分权重：60%
         │  ├─ 逆向得分权重：40%
         │  └─ 最终阈值：50%
         ↓
    活体决策
    ├─ 是：返回 true
    └─ 否：返回 false
```

### 可靠性级别

| 级别 | 检测方法 | 数据来源 | 可靠性 | 说明 |
|-----|---------|--------|-------|------|
| 🔴 最高 | 单应性变换约束 | 2D坐标 | ✅✅✅ | 纯几何，物理定律 |
| 🔴 最高 | 交叉比率不变性 | 2D坐标 | ✅✅✅ | 射影定理，无法欺骗 |
| 🟡 高 | 透视变换规律 | 2D坐标 | ✅✅ | 几何约束 |
| 🟡 高 | 眨眼时间 | 时间戳 | ✅✅ | 生物特征 |
| 🟡 高 | 眼睛对称性 | 2D坐标 | ✅✅ | 行为模式 |
| 🟢 中 | Z坐标深度 | 推断值 | ✅ | 可能被欺骗 |

---

## 正向检测

### 1. 眼睛微动检测（Eye Fluctuation）

#### 方法：眼睛宽高比（EAR - Eye Aspect Ratio）

计算公式：

$$EAR = \frac{||P_2 - P_6|| + ||P_3 - P_5||}{2 \times ||P_1 - P_4||}$$

其中 $P_1, ..., P_6$ 是眼周的 6 个关键点：
- $P_1, P_4$：眼睛左右两端（内外眼角）
- $P_2, P_3, P_5, P_6$：上下眼睑

```
     P2      P3
   ╱────────────╲
  P1            P4   (眼睛宽度 h = ||P1 - P4||)
   ╲────────────╱
     P6      P5
     
  眼睛高度 v = ||P2-P6|| + ||P3-P5|| / 2
  EAR = v / h
```

#### 特征

| 状态 | EAR 值 | 说明 |
|-----|-------|------|
| 睁眼 | 0.4 - 0.5 | 正常 |
| 眨眼（闭眼） | 0.1 - 0.2 | 快速下降后上升 |
| 微眨 | 0.25 - 0.35 | 微妙的闭合 |

#### 防护机制

1. **眼睛对称性检测**
   ```
   相关系数 = Pearson(左眼EAR变化, 右眼EAR变化)
   真人: 相关系数 > 0.7  (同步眨眼)
   照片: 相关系数 ≈ 0    (无法同步)
   ```

2. **眨眼时间检测**
   ```
   真人眨眼：100-400ms（闭眼阶段）
   快眨眼：100-200ms
   慢眨眼：200-400ms
   照片：无法产生任何眨眼
   ```

3. **眨眼周期检测**
   ```
   分析 EAR 序列的振荡模式
   - 真人：完整周期（下降→平台→上升）
   - 照片：单调或随机波动
   ```

4. **运动-形变相关性**
   ```
   皮尔逊相关系数 = Corr(刚性运动, EAR变化)
   真人：低相关(<0.3)  (头动和眨眼独立)
   照片：高相关(>0.7)  (两者都是平移)
   ```

### 2. 嘴巴微动检测（Mouth Fluctuation）

#### 方法：嘴巴宽高比（MAR - Mouth Aspect Ratio）

计算公式：

$$MAR = \frac{||P_{上} - P_{下}||}{||P_{左} - P_{右}||}$$

- $P_{上}, P_{下}$：上下嘴唇的 y 坐标
- $P_{左}, P_{右}$：嘴角的 x 坐标

#### 特征

| 动作 | MAR 变化 | 说明 |
|-----|---------|------|
| 闭嘴 | ≈ 0.1 | 基线 |
| 微张 | 0.15 - 0.25 | 轻微张口 |
| 大张 | 0.3 - 0.5 | 说话、张大嘴 |

### 3. 面部肌肉微动检测（Muscle Movement）

#### 方法：关键点位置变化

采样肌肉关键点：
- 嘴角（61, 291）
- 眉毛（46, 53, 276, 283）
- 脸颊（127, 356）

#### 计算框架

1. **相邻帧位移**
   ```
   d_i = ||P_i(帧t) - P_i(帧t-1)||
   ```

2. **归一化处理**
   ```
   由于坐标是相对于图像左上角，需要归一化：
   d_norm = (P_i(帧t) - 人脸框左上角) / 人脸框大小
          - (P_i(帧t-1) - 人脸框左上角) / 人脸框大小
   ```

3. **刚性运动检测**
   ```
   计算所有采样点的运动向量
   如果所有向量方向一致（照片纯平移）→ 高刚性分数
   如果向量方向不同（真人复杂运动）→ 低刚性分数
   
   刚性分数 = (1 - 方向变异) × (1 - 幅度变异)
   真人：刚性分数 < 0.5
   照片：刚性分数 > 0.8
   ```

#### 防护

- 不直接拒绝刚性运动（真人也会摇头）
- 结合其他生物特征判断

---

## 逆向检测

> **核心思想**：照片必须满足**物理约束**，而这些约束无法被欺骗

### 1. 单应性变换约束（Homography Constraint）

#### 原理

平面物体（照片）在不同视角下的投影满足单应变换：

$$\mathbf{p}_2 = H \cdot \mathbf{p}_1$$

其中：
- $\mathbf{p}_1$：第一帧的关键点
- $\mathbf{p}_2$：第二帧的关键点
- $H$：3×3 单应矩阵

#### 推导

对于平面上的点，利用 4 对对应点可以计算单应矩阵：

```
选择 4 个基准点（面部四角）
    ↓
拟合仿射变换（单应的近似）
    ↓
用变换预测其他点的位置
    ↓
计算预测误差
```

#### 判据

```
假设误差阈值为 ε = 5% 关键点间距

相对误差 = Σ||预测位置 - 实际位置|| / 关键点数 / 脸宽

真人：相对误差 > 8%  （不满足平面约束）
照片：相对误差 < 2%  （满足平面约束）

平面得分 = max(0, 1 - 相对误差/5%)
```

### 2. 交叉比率不变性（Cross-Ratio Invariance）

#### 原理

**射影定理**：平面上共线四点的交叉比率在透视变换下保持不变

$$CR(A,B,C,D) = \frac{|AC| \times |BD|}{|BC| \times |AD|}$$

#### 应用

选择面部中线上的共线点：额头 → 鼻梁 → 鼻尖 → 嘴 → 下巴

对于照片（点共面）：
```
无论如何旋转照片，这 5 个点的交叉比率保持恒定
CR(帧1) ≈ CR(帧2) ≈ CR(帧3) ...
```

对于真人（点不共面）：
```
头部旋转时，各点的相对位置变化
CR(帧1) ≠ CR(帧2) ≠ CR(帧3)
```

#### 判据

```
计算交叉比率序列：CR = [cr_1, cr_2, ..., cr_n]

变异系数 cv = σ(CR) / μ(CR)

真人：cv > 0.15  （变化明显）
照片：cv < 0.05  （几乎恒定）

不变性得分 = max(0, 1 - cv/0.1)
```

### 3. 透视变换规律（Perspective Transform Pattern）

#### 原理

照片水平倾转时，左右脸的宽度比例会按照透视规律**平滑变化**：

```
照片倾左：  右脸变窄 ←→ 左脸变宽
照片倾右：  左脸变窄 ←→ 右脸变宽
真人摇头：  左右脸都会变化，但不遵循严格的平滑规律
```

#### 计算

```
宽度比 ratio_i = 左脸宽度 / 右脸宽度

检测变化的平滑度：
对于相邻 3 帧 i-1, i, i+1
  Δ1 = ratio_i - ratio_{i-1}
  Δ2 = ratio_{i+1} - ratio_i
  
  if Δ1 × Δ2 ≥ 0:  // 变化方向一致（平滑）
    平滑计数 += 1

平滑度 = 平滑变化帧数 / 总帧数

真人：平滑度 < 0.5   （复杂运动）
照片：平滑度 > 0.8   （单调变化）
```

### 4. Z 坐标深度分析（Depth Consistency）

#### 原理

MediaPipe 为每个关键点推断 Z 坐标（相对深度）：
- 真人：不同区域的 Z 坐标有明显差异
  - 鼻子：0.1-0.2（凸出）
  - 眼睛：0.05-0.1
  - 下巴：-0.05-0.05（后退）
  
- 照片：所有点在一个平面，Z 坐标变异很小

#### 检测

```
采样关键点：额头(10)、下巴(152)、左脸颊(234)、右脸颊(454) 等

计算 Z 坐标变异系数：
cv_z = σ(Z值) / μ(Z值)

真人：cv_z > 0.3   （有深度差异）
照片：cv_z < 0.15  （平面）

平面性得分 = max(0, 1 - cv_z/0.15)
```

#### ⚠️ 局限性

这个检测可能被以下方法欺骗：
- 使用 3D 面具
- 高质量的 3D 打印人脸模型
- 某些生成式 AI（如 StyleGAN）生成的超逼真图像

**因此仅作为辅助参考，权重设置较低（10%）**

---

## 综合决策

### 检测指标

首先计算以下指标：

| 指标 | 来源 | 说明 |
|------|------|------|
| **照片几何检测** | 逆向检测 | `photoGeometry.confidence` (0-1) |
| **生物特征** | 正向检测 | `hasEyeMovement` \|\| `hasMouthMovement` \|\| `hasMuscleMovement` |
| **刚性运动分数** | 肌肉检测 | `muscleActivity.rigidityScore` (0-1) |
| **透视攻击检测** | 眼睛检测 | `eyeActivity.isPerspectiveAttack` (布尔值) |
| **脸部形状稳定性** | 几何稳定性 | `faceShapeStability` (0-1) |

### 决策矩阵（优先级制）

实际使用的是**分层条件判定**，而非简单的加权平均。这样可以确保最高优先级的检测优先生效：

#### 第一层：照片几何检测（最高优先级）

```
if 照片几何检测置信度 > 0.75:
    返回 false  // 直接拒绝，不需要进一步检查
```

**原因**：照片几何约束（单应性、交叉比率）遵循物理定律，无法被欺骗。

#### 第二层：生物特征 vs 几何可疑度

```
if 照片几何检测置信度 > 0.5:
    // 照片可疑度中等以上（中等风险）
    返回 (有生物特征 AND 不是透视攻击)
else:
    // 照片可疑度较低（低风险）
    返回 (有生物特征 AND 不是透视攻击) 
         OR (刚性运动 > 0.7 AND 脸部不稳定 AND 不是透视攻击)
```

### 详细决策表

| 照片几何置信度 | 生物特征 | 透视攻击 | 刚性运动 | 脸部稳定 | 判定 | 说明 |
|-------------|---------|---------|---------|---------|------|------|
| **>0.75** | - | - | - | - | ❌ **拒绝** | 照片特征明确，无需其他检查 |
| 0.5-0.75 | ✅ | ❌ | - | - | ✅ **通过** | 有生物特征覆盖几何可疑 |
| 0.5-0.75 | ❌ | - | - | - | ❌ **拒绝** | 照片可疑且无生物特征 |
| **<0.5** | ✅ | ❌ | - | - | ✅ **通过** | 低风险 + 有生物特征 |
| <0.5 | ❌ | ✅ | - | - | ❌ **拒绝** | 检测到透视攻击 |
| <0.5 | ❌ | ❌ | >0.7 | <0.9 | ✅ **通过** | 刚性运动 + 脸部变化 |
| <0.5 | ❌ | ❌ | ≤0.7 | - | ❌ **拒绝** | 无生物特征，刚性不足 |

### 核心逻辑代码

```typescript
if (photoConfidence > 0.75) {
    // 第一层：照片几何检测决定性判定
    return false  // 直接拒绝
}

if (photoConfidence > 0.5) {
    // 第二层：中等风险，需要有生物特征且无透视攻击
    return hasBioFeatures && !isPerspectiveAttack
} else {
    // 第三层：低风险，考虑多个因素
    const hasRigidMotion = rigidityScore > 0.7
    const isPhotoLikely = faceShapeStability > 0.9
    
    return (hasBioFeatures && !isPerspectiveAttack) 
        || (hasRigidMotion && !isPhotoLikely && !isPerspectiveAttack)
}
```

### 为什么采用分层条件判定而非加权平均？

1. **物理约束的绝对性**
   - 照片的几何约束无法被破坏
   - 当置信度足够高时，应该优先级最高

2. **生物特征的可变性**
   - 人在放松、疲劳时生物特征可能减弱
   - 不应该因此自动拒绝（虚假拒绝率提升）

3. **攻击多样性**
   - 不同类型的攻击（照片、视频、面具）有不同特征
   - 需要根据检测结果灵活组合判据

4. **实时性要求**
   - 分层判定在早期就能做出决策
   - 无需等待所有检测完成

### 时间序列稳定性

虽然单帧决策使用的是条件逻辑，但在实际应用中通常需要多帧验证：

```typescript
// 维护最近 N 帧的决策历史
livenessHistory = [决策_1, 决策_2, ..., 决策_N]

// 最终决策采用多数投票或信心积累
if count(livenessHistory == true) > 0.6 × N:
    返回 true  // 活体 (高置信度)
else if count(livenessHistory == true) > 0.4 × N:
    返回 true  // 活体 (中等置信度)
else:
    返回 false // 欺骗
```

---

## 坐标归一化

### 问题

MediaPipe 返回的坐标是相对于**图像左上角**的像素坐标：

```
帧1：人脸在左边  → 鼻尖 = (100, 200)
帧2：人脸在右边  → 鼻尖 = (400, 200)  // 同一个点，坐标完全不同！
```

直接比较绝对坐标会导致错误结论。

### 解决方案

```
归一化坐标 = (原始坐标 - 人脸框左上角) / 人脸框大小
           ∈ [0, 1]
```

### 优势

```
帧1：人脸在左边  → 鼻尖 = (0.45, 0.50)  （相对于人脸）
帧2：人脸在右边  → 鼻尖 = (0.45, 0.50)  （相对于人脸）// 坐标一致！
```

所有几何约束检测都使用归一化坐标，消除人脸移动的影响。

---

## 性能指标

### 计算复杂度

| 操作 | 时间复杂度 |
|-----|-----------|
| MediaPipe 推理 | O(1) ~100ms |
| 关键点提取 | O(468) ~1ms |
| 坐标归一化 | O(468) ~1ms |
| EAR/MAR 计算 | O(1) ~1ms |
| 单应性拟合 | O(n) ~5ms |
| 所有检测 | O(n) ~20ms |

### 准确率指标

目标场景：防止用照片欺骗的活体检测

| 指标 | 真人（活体） | 照片 | 视频回放 |
|-----|-----------|------|--------|
| 检测率 | 95-99% | 95-99% | 90-95% |
| 误拒率 | 1-5% | - | - |
| 虚假接受率 | - | 1-5% | 5-10% |

### 延迟

| 场景 | 延迟 |
|-----|------|
| 单帧检测 | ~150ms |
| 前5帧平均 | ~200ms |
| 前15帧平均 | ~300ms |

---

## 常见问题

### Q1：为什么要使用双重检测？

**A**：
- **正向检测**速度快，对微妙动作敏感
- **逆向检测**更加鲁棒，遵循物理定律
- 两者结合：快速响应 + 高置信度

### Q2：照片加入运动（如放在摇摇棒上）能否欺骗？

**A**：
- ✅ 单应性约束仍然成立（照片仍是平面）
- ✅ 交叉比率仍然不变（共线点关系不变）
- ✅ 运动-形变相关性为 0（两者都是刚性平移）

**结论**：无法欺骗

### Q3：为什么 Z 坐标不可靠？

**A**：
MediaPipe 的 Z 坐标是从 2D RGB 图像用神经网络推断的，不是真实深度：
- 对真人：推断结果准确
- 对高分辨率照片：由于照片上有阴影、透视感，神经网络也会推断出"立体感"
- 对生成式 AI 图像：可能推断出逼真但实际不存在的深度

### Q4：3D 面具能否欺骗？

**A**：
取决于 3D 面具的质量：
- **低质量面具**：无法通过所有生物特征检测（无眨眼、无微动）
- **高质量可动面具**：可能通过正向检测，但单应性约束会检出（面具有额外的几何变形）
- **完美面具**：理论上极难，但会消耗巨大成本

### Q5：多少帧才能做出可靠决策？

**A**：
```
最少帧数：5-10 帧（约 0.17-0.33 秒@30fps）
推荐帧数：15-30 帧（约 0.5-1 秒）
最优帧数：30+ 帧（包含完整眨眼周期）
```

### Q6：如何调整灵敏度？

**A**：
```typescript
// 降低灵敏度（减少误拒）
detector.config.frameBufferSize = 20;
detector.config.eyeMinFluctuation = 0.012;
detector.config.activityThreshold = 0.15;

// 提高灵敏度（减少虚假接受）
detector.config.frameBufferSize = 10;
detector.config.eyeMinFluctuation = 0.004;
detector.config.activityThreshold = 0.3;
```

### Q7：弱光/黑暗环境能检测吗？

**A**：
- MediaPipe 的鲁棒性有限，需要足够的光线
- **推荐照度**：> 200 lux（正常室内光）
- **暗光**（< 50 lux）：可能无法检测到准确的关键点

### Q8：眼镜/墨镜会影响检测吗？

**A**：
- **普通眼镜**：通常不影响（关键点在眼睛周围，不是瞳孔）
- **深色墨镜**：可能影响 EAR 的可靠性，但其他生物特征仍有效
- **反光眼镜**：可能导致关键点检测失败

---

## 参考资源

### 关键论文

- MediaPipe Face Mesh: [Real-time Face Detection and Multi-face Tracking](https://arxiv.org/abs/1906.08172)
- Eye Aspect Ratio: [Real-Time Eye Blink Detection using Facial Landmarks](https://vision.fe.uni-lj.si/cvww2016/proceedings/papers/05.pdf)
- 单应性变换: [Multiple View Geometry in Computer Vision](https://www.robots.ox.ac.uk/~vgg/data/data-mview.html)
- 交叉比率与射影定理: [Projective Geometry](https://en.wikipedia.org/wiki/Cross-ratio)

### 数据集

- **活体检测数据集**：
  - NUAA 数据集
  - CASIA-FASD
  - MSU-MFSD
  - Replay-Attack
  - OULU-NPU

---

## 版本历史

| 版本 | 日期 | 变更 |
|-----|------|------|
| 1.0 | 2026-01-16 | 初始版本，双重检测策略 |

---

**更新于**：2026-01-16
