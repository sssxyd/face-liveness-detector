# 活体检测中的 analyzeMotion 运动检测算法分析

## 目录
1. [检测算法概览](#检测算法概览)
2. [各种检测算法详解](#各种检测算法详解)
3. [需要的帧数分析](#需要的帧数分析)
4. [算法时间要求](#算法时间要求)
5. [实际应用建议](#实际应用建议)

---

## 检测算法概览

`analyzeMotion` 方法采用**双重检测策略**和**6重投票制**：

```
活体检测流程：
┌─ 正向检测（生物特征） ──┬─ 眼睛波动检测 (Eye Fluctuation)
│                       ├─ 嘴巴波动检测 (Mouth Fluctuation)
│                       └─ 面部肌肉微动检测 (Muscle Movement)
│
├─ 逆向检测（照片几何） ──┬─ 照片平面性检测 (Photo Planarity)
│                       ├─ 刚性运动检测 (Rigid Motion)
│                       ├─ 单应性约束检测 (Homography)
│                       ├─ 透视变换检测 (Perspective Pattern)
│                       ├─ 交叉比率检测 (Cross Ratio)
│                       └─ 深度一致性检测 (Depth Consistency)
│
└─ 综合投票 ──────────────→ 最终活体判断
```

---

## 各种检测算法详解

### 1. 眼睛波动检测 (Eye Aspect Ratio - EAR)

#### 算法原理
检测眼睛开度的变化，识别眨眼和眼睛微动。

#### 计算公式
$$\text{EAR} = \frac{\|p_2 - p_6\| + \|p_3 - p_5\|}{2 \times \|p_1 - p_4\|}$$

- $p_1, p_4$：眼睛左右角（水平距离）
- $p_2, p_6$；$p_3, p_5$：眼睛上下轮廓（垂直距离）

#### 防护机制（6重检测）

| 防护层级 | 防护名称 | 防护内容 | 检测目标 |
|--------|--------|--------|---------|
| 1 | 往复波动检测 | 检测 EAR 是否呈现往复波动 | 区分真实眨眼 vs 透视畸变 |
| 2 | 真实眨眼检测 | 检测下降→保持→上升的眨眼周期 | 区分完整眨眼 vs 噪声 |
| 3 | 最近活动检测 | 检测最近帧是否有变化 | 确保实时动作 |
| 4 | 左右眼对称性 | 检测左右眼变化同步性 | 真实眨眼双眼同时 |
| 5 | 眨眼时间模式 | 检测眨眼周期是否在 100-400ms | 区分真实眨眼 vs 照片摆动 |
| 6 | 运动-形变相关性 | 检测眼睛运动与面部形变关联 | 检测透视畸变攻击 |

#### 关键参数
- **最小波动阈值**：`0.008`（检测微妙变化）
- **标准差阈值**：`0.005`
- **波动范围阈值**：`0.02`（用于判定明显波动）
- **眨眼时间范围**：`100-400ms`（3-12帧@30fps）

#### 输出指标
```typescript
{
  score: number              // 综合评分 (0-1)
  stdDev: number            // 标准差
  fluctuation: number       // 波动范围 (max - min)
  hasMovement: boolean      // 是否检测到真实动作
  isPerspectiveAttack?: boolean  // 是否是透视畸变攻击
}
```

---

### 2. 嘴巴波动检测 (Mouth Aspect Ratio - MAR)

#### 算法原理
检测嘴巴开度变化，识别张嘴、微笑等口腔动作。

#### 计算方式
```
MAR = 垂直距离（上下唇） / 水平距离（嘴巴宽度）
```

#### 防护机制

| 防护层级 | 防护名称 | 防护内容 |
|--------|--------|--------|
| 1 | 真实张嘴检测 | 检测下降→保持→上升的完整张嘴周期 |
| 2 | 最近活动检测 | 检测最近是否有嘴巴活动 |

#### 关键参数
- **最小波动阈值**：`0.005`（检测微妙变化）
- **标准差阈值**：`0.003`
- **变化判定阈值**：`0.008`（检测下降/上升）
- **最近开度变化**：`> 0.015`（检测最近动作）

#### 输出指标
```typescript
{
  score: number        // 综合评分 (0-1)
  stdDev: number      // 标准差
  fluctuation: number // 波动范围
  hasMovement: boolean // 是否检测到真实动作
}
```

---

### 3. 面部肌肉微动检测 (Muscle Movement)

#### 算法原理
检测面部关键点的位置变化，识别肌肉微妙收缩（脸颊、眉毛、嘴角等）。

#### 关键点选择
```typescript
肌肉关键点 = [
  61, 291,      // 嘴角
  46, 53,       // 左眉
  276, 283,     // 右眉
  127, 356      // 脸颊
]
```

#### 检测方法

1. **使用归一化坐标**：消除人脸位置和尺寸影响
   - 将原始坐标映射到人脸局部坐标系（0-1 范围）
   - 避免人脸在画面中的移动影响判断

2. **计算帧间距离**：
   ```
   distance = sqrt((x₁-x₂)² + (y₁-y₂)²)  // 归一化坐标中的距离
   ```

3. **计算变异性**：
   ```
   variation = stdev(distances)  // 相邻帧距离的标准差
   avgDist = mean(distances)     // 平均距离
   ```

4. **刚性运动检测**：
   - 检测运动向量的方向和幅度一致性
   - 照片被拿着旋转/平移 → 所有点运动方向一致（刚性）
   - 真实肌肉运动 → 不同部位独立运动（非刚性）

#### 关键参数
- **最小变异阈值**：`0.001`（归一化坐标）
- **最小平均距离**：`0.005`（归一化坐标）
- **方向一致性阈值**：`0.5 rad`（刚性运动的方向偏差）
- **幅度一致性阈值**：使用变异系数（CV）

#### 输出指标
```typescript
{
  score: number           // 综合评分 (0-1)
  variation: number       // 标准差
  hasMovement: boolean    // 是否检测到真实动作
  rigidityScore?: number  // 刚性运动得分（照片的特征）
}
```

---

### 4. 照片平面性检测 (Photo Planarity)

#### 算法原理
利用 Z 坐标（MediaPipe 推断的深度）检测照片的平面特征。

#### 核心思想
- **照片特征**：所有关键点的 Z 坐标相同（都在同一个平面）
- **真实人脸**：不同区域深度不同（鼻子突出，眼睛凹陷，下巴角度等）

#### 计算步骤
```
1. 采样关键点的Z坐标
   samplePoints = [10, 152, 33, 263, 61, 291, 1, 234, 454]
   
2. 计算 Z 坐标的变异系数
   zMean = mean(zValues)
   zStdDev = stdev(zValues)
   zVarianceRatio = zStdDev / zMean
   
3. 判断平面性
   if zVarianceRatio < 0.15:  平面（照片）
   if zVarianceRatio > 0.3:   立体（活体）
   
4. 平面性评分
   planarity = max(0, (0.15 - zVarianceRatio) / 0.15)
```

#### 关键参数
- **照片判定阈值**：`z_variance_ratio < 0.15`
- **活体判定阈值**：`z_variance_ratio > 0.3`

#### 局限性
⚠️ **重要**：MediaPipe 返回的 Z 坐标是从 2D 图像**推断**出来的，而非真实物理深度！
- 对真实人脸：推断准确
- 对照片：也可能推断出"假"的 3D 结构（因为照片看起来也像 3D）

因此，此方法**不能单独依赖**，必须结合其他几何约束检测。

---

### 5. 刚性运动检测 (Rigid Motion Detection)

#### 算法原理
检测所有关键点的运动向量是否方向和幅度一致（刚性特征）。

#### 关键点选择
```typescript
samplePoints = [
  33, 263,      // 左右眼外角
  362, 133,     // 左右眼内角
  234, 454,     // 左右脸颊边缘
  10, 152,      // 额头、下巴
  61, 291       // 嘴角
]
```

#### 计算方法

1. **提取运动向量**：
   ```
   frame_t: [p₁, p₂, ..., p₁₀]
   frame_{t+1}: [p₁', p₂', ..., p₁₀']
   
   motion_vector = (p₁' - p₁, p₂' - p₂, ..., p₁₀' - p₁₀)
   ```

2. **计算方向一致性**：
   ```
   angle = atan2(dy, dx)  // 每个点的运动方向
   angleStdDev = stdev(angles)
   // 刚性运动：所有向量方向相同，angleStdDev ≈ 0
   // 肌肉运动：各点方向不同，angleStdDev > 0.3
   ```

3. **计算幅度一致性**：
   ```
   magnitude = sqrt(dx² + dy²)
   magnitudeCV = stdev(magnitudes) / mean(magnitudes)
   // 刚性运动：所有向量幅度相似，CV ≈ 0
   // 肌肉运动：各点幅度不同，CV > 0.2
   ```

4. **综合刚性评分**：
   ```
   rigidityScore = 
     max(0, 1 - angleStdDev / 0.5) × 
     max(0, 1 - magnitudeCV)
   
   值域：[0, 1]
   0.0 = 完全非刚性（肌肉运动）
   1.0 = 完全刚性（照片被拿着旋转）
   ```

#### 输出指标
- **刚性得分**：0-1，越高越可能是照片被旋转

---

### 6. 单应性约束检测 (Homography Constraint)

#### 算法原理
利用平面几何的不变性检测照片。

#### 核心思想
- **照片特征**：平面物体的投影变换可以用单应矩阵 $H$ 完全描述
- **一致性检测**：当视角改变时，照片上所有关键点的变换应该满足同一个 $H$
- **活体特征**：真实人脸的 3D 运动不能用单个 $H$ 完全描述

#### 计算步骤
```
1. 获取相邻两帧的关键点
   frame_i: P_i = [p₁, p₂, ..., p₄₆₈]
   frame_{i+1}: P_{i+1} = [p₁', p₂', ..., p₄₆₈']
   
2. 使用 RANSAC 算法估算单应矩阵 H
   P_{i+1} ≈ H × P_i
   
3. 计算重投影误差
   error = ||P_{i+1} - H × P_i||²  // 所有点的误差
   
4. 判断是否满足平面约束
   if error < threshold:  照片（所有点误差小，满足平面约束）
   else:                 活体（误差大，不能用单应矩阵描述）
```

#### 关键参数
- **误差阈值**：通常 `< 10 pixels` 认为满足平面约束
- **采样点数**：建议 >= 50 个点以提高稳健性

#### 优势 ⭐⭐⭐⭐⭐
- 基于**纯几何不变性**，物理定律
- 无法欺骗（即使是高质量照片或视频）
- 不依赖光流等估计方法

---

### 7. 透视变换模式检测 (Perspective Pattern)

#### 算法原理
利用透视变换的规律性检测照片。

#### 核心思想
当一张照片从不同视角被观看时：
- 照片中的人脸比例关系遵循严格的透视变换规律
- 真实人脸可以做出各种不规则的 3D 旋转，破坏透视规律

#### 检测方法
```
1. 归一化关键点坐标（消除尺度和平移影响）
2. 计算相邻帧的仿射变换（不是单应）
   T = affine_transform(P_i, P_{i+1})
   
3. 检查变换矩阵的规律性
   if 所有帧的变换矩阵都是相似的缩放+旋转：
     → 照片（规律的透视变换）
   else:
     → 活体（不规则的 3D 运动）
```

#### 评分规则
```
perspectiveScore = 相邻帧变换矩阵的一致性
值域：[0, 1]
0.0 = 完全不规律（活体）
1.0 = 完全规律（照片）
```

---

### 8. 交叉比率不变性检测 (Cross Ratio Invariance)

#### 算法原理
利用射影几何的基本不变量检测照片。

#### 核心知识
**交叉比率（Cross Ratio）**：在射影变换下保持不变

对于四个共线点 A, B, C, D，交叉比定义为：
$$CR = \frac{|AC| \times |BD|}{|AD| \times |BC|}$$

性质：
- 在任何射影变换（包括透视）下，CR 值保持不变
- 照片被看成不同角度时，四个共线关键点的 CR 应该保持不变
- 真实人脸的 3D 运动可能改变 CR（因为脸部是 3D 的）

#### 计算步骤
```
1. 选择四个共线的关键点
   例如：嘴巴四个点 [p_left, p_left_mid, p_right_mid, p_right]
   
2. 计算交叉比（各帧）
   CR_frame_i = compute_cross_ratio(points_frame_i)
   CR_frame_{i+1} = compute_cross_ratio(points_frame_{i+1})
   
3. 计算不变性
   if |CR_i - CR_{i+1}| < epsilon:
     → 照片（CR 保持不变）
   else:
     → 活体（CR 改变）
   
4. 计算不变性得分
   invarianceScore = 1 / (1 + |CR变化|)  // 越不变分数越高
```

#### 评分规则
```
crossRatioScore = 交叉比不变性程度
值域：[0, 1]
0.0 = 高度变化（活体）
1.0 = 完全不变（照片）
```

#### 优势 ⭐⭐⭐⭐
- 基于**射影几何基本定理**
- 不依赖摄像机参数
- 对照片非常敏感

---

### 9. 深度一致性检测 (Depth Consistency)

#### 算法原理
检查 Z 坐标（深度）的跨帧一致性。

#### 核心思想
- **照片特征**：所有关键点的 Z 坐标在所有帧中基本不变（都在同一平面）
- **活体特征**：人脸可以做出各种运动，不同部位的相对深度可能改变

#### 计算步骤
```
1. 收集多帧的 Z 坐标
   Z_history = [[z₁¹, z₂¹, ..., z₄₆₈¹], [z₁², ...], ...]
   
2. 计算各点的 Z 坐标变异性
   for each point i:
     z_variance_i = var(Z_history[:, i])
   
3. 统计全体点的方差
   avg_variance = mean(z_variance_i)
   
4. 判断深度变化
   if avg_variance < threshold:  照片（深度恒定）
   else:                         活体（深度有变化）
```

#### 评分规则
```
depthVariation = Z 坐标的平均变异性
值域：[0, 1]
0.0 = 变化很小（照片）
1.0 = 变化很大（活体）
```

---

### 10. 跨帧深度模式检测 (Cross-Frame Depth Pattern)

#### 算法原理
检查深度变化是否存在规律的平面性模式。

#### 核心思想
```
照片旋转时：
- Z 坐标基本不变，可能有均匀的伪深度变化
- 这种变化遵循规律的平面变换模式

真实人脸运动时：
- Z 坐标可能有随机的、不规律的变化
- 各点的深度独立变化
```

#### 计算方法
```
1. 拟合平面模型（使用最小二乘法）
   Z = a*X + b*Y + c  // 拟合所有点的Z坐标
   
2. 计算拟合残差
   residuals = |Z_actual - Z_fitted|
   
3. 计算平面模式得分
   if residuals << Z_variance:
     → 强烈的平面模式（照片）
   else:
     → 随机的 Z 变化（活体）
```

#### 评分规则
```
planarPattern = 平面模式强度
值域：[0, 1]
0.0 = 无明显平面模式（活体）
1.0 = 完全平面模式（照片）
```

---

## 需要的帧数分析

### 1. 帧缓冲区大小配置

```typescript
const DEFAULT_OPTIONS = {
  frameBufferSize: 15,                    // 15帧 (0.5秒@30fps)
  eyeMinFluctuation: 0.008,               // 眼睛最小波动
  mouthMinFluctuation: 0.005,             // 嘴巴最小波动
  muscleMinVariation: 0.002,              // 肌肉最小变化
  activityThreshold: 0.2                  // 活动度阈值
}
```

### 2. 各检测算法的最小帧数要求

| 检测算法 | 最少帧数 | 建议帧数 | 原因 |
|--------|---------|---------|------|
| 眼睛波动检测 | 3 帧 | 5-15 帧 | 需要足够样本判断波动模式 |
| 嘴巴波动检测 | 3 帧 | 5-15 帧 | 需要完整的张嘴/闭嘴周期 |
| 面部肌肉检测 | 2 帧 | 5-15 帧 | 需要相邻帧计算位移 |
| 照片平面性检测 | 1 帧 | 1 帧 | 单帧分析 Z 坐标 |
| 刚性运动检测 | 2 帧 | 5-15 帧 | 需要多帧确认运动模式 |
| 单应性约束检测 | 2 帧 | 5+ 帧 | 2帧即可，但多帧提高精度 |
| 透视变换检测 | 3 帧 | 5-15 帧 | 需要多帧观察变换规律 |
| 交叉比率检测 | 2 帧 | 5+ 帧 | 2帧即可比较 |
| 深度一致性检测 | 3 帧 | 5-15 帧 | 需要多帧统计深度变化 |
| 跨帧深度模式 | 3 帧 | 5-15 帧 | 需要多帧拟合平面 |

### 3. 不同场景的帧数需求

#### 场景 A：快速响应（最少帧数）
```
目标：尽快给出活体判断
最少帧数：5 帧（~167ms@30fps）

配置：
{
  frameBufferSize: 5
}

可靠的检测：
✅ 简单的眨眼
✅ 张嘴
✅ 头部微动
✅ 严重的刚性运动（照片拿着旋转）

限制：
❌ 无法检测复杂的透视畸变
❌ 假阴性率可能较高（活体判定不足）
❌ 防护强度降低
```

#### 场景 B：平衡模式（推荐配置）
```
目标：在速度和准确率之间平衡
最少帧数：10-12 帧（~333-400ms@30fps）

配置：
{
  frameBufferSize: 15  // 允许缓冲最多 15 帧
}

实际生效条件：
- isReady() 返回 true 时：>= 5 帧
- 但系统会继续收集数据直到 15 帧

可靠的检测：
✅ 各种形式的眨眼
✅ 表情变化
✅ 头部运动（各方向）
✅ 照片静止或缓慢旋转
✅ 单应性约束违反
✅ 基本的透视变换违反
✅ 刚性运动检测

防护强度：⭐⭐⭐⭐
```

#### 场景 C：高安全性（严格模式）
```
目标：最大化防护强度
最少帧数：15 帧（~500ms@30fps）

配置：
{
  frameBufferSize: 15
  // + 启用所有逆向检测
}

可靠的检测：
✅ 所有场景 B 的检测
✅ 复杂的透视畸变
✅ 高质量视频回放
✅ 深度不一致性
✅ 跨帧深度模式

防护强度：⭐⭐⭐⭐⭐

成本：
⏱️ 响应时间：~500ms
📱 用户体验：相对较长
🎯 误判率：最低
```

### 4. 帧数与检测准确率的关系

```
帧数        可靠性    响应时间  推荐场景
─────────────────────────────────────────
5 帧        ⭐⭐       ~170ms    快速人脸认证
10 帧       ⭐⭐⭐      ~333ms    平衡应用
15 帧       ⭐⭐⭐⭐⭐   ~500ms    高安全应用
20+ 帧      ⭐⭐⭐⭐⭐   700ms+    金融/司法级
```

### 5. 实际代码中的帧数检查

```typescript
// 初始化检查
isReady(): boolean {
  return this.normalizedLandmarksHistory.length >= 5
  //     检测需要至少 5 帧才能开始运行
}

// 在 analyzeMotion 中
if (!this.isReady()) {
  return this.createEmptyResult({
    reason: '数据收集中，帧数不足',
    collectedFrames: this.normalizedLandmarksHistory.length
  })
}
```

### 6. 帧数不足时的处理

```typescript
getMessage(): string {
  if (this.details.frameCount < 5) {
    return '数据不足，无法进行活体检测'
    //      明确告知用户需要更多数据
  }
  // ...
}
```

---

## 算法时间要求

### 1. 每帧处理时间

| 检测模块 | CPU 消耗 | 处理时间 | 说明 |
|--------|---------|---------|------|
| 关键点提取 | 低 | ~5ms | 直接从 MediaPipe 获取 |
| EAR 计算 | 低 | ~1ms | 简单的几何计算 |
| MAR 计算 | 低 | ~1ms | 简单的几何计算 |
| 肌肉检测 | 中 | ~5ms | 多点距离计算和统计 |
| 照片平面性 | 低 | ~2ms | Z 坐标方差计算 |
| 刚性运动检测 | 中 | ~8ms | 角度和向量计算 |
| 单应性检测 | **高** | **20-30ms** | RANSAC + 矩阵运算 |
| 透视变换检测 | **高** | **15-20ms** | 仿射变换计算 |
| 交叉比率检测 | 低 | ~3ms | 距离比例计算 |
| 深度一致性检测 | 低 | ~3ms | 方差计算 |
| 跨帧深度模式 | 中 | ~10ms | 平面拟合 |
| **总计** | | **~50-100ms** | 取决于启用模块 |

### 2. 总检测延迟

```
单帧延迟：50-100ms
缓冲帧数：5 帧（最少）
总延迟：单帧延迟 + 帧缓冲时间

计算：
快速模式（5帧）：
  = 50-100ms + (5帧 / 30fps) 
  = 50-100ms + 167ms 
  = ~220ms（总体）

平衡模式（15帧）：
  = 50-100ms + (15帧 / 30fps) 
  = 50-100ms + 500ms 
  = ~550-600ms（总体）
```

### 3. 帧率影响

| 帧率 | 缓冲帧数 | 缓冲时间 | 示例场景 |
|-----|---------|---------|---------|
| 15 fps | 5 帧 | 333ms | 低端设备或网络视频 |
| 24 fps | 5 帧 | 208ms | 视频编码标准 |
| 30 fps | 5 帧 | 167ms | 移动设备常见 |
| 60 fps | 5 帧 | 83ms | 高端设备 |
| 120 fps | 5 帧 | 42ms | 旗舰设备 |

---

## 实际应用建议

### 1. 配置建议

```typescript
// 移动应用（快速体验）
const mobileConfig = {
  frameBufferSize: 10,           // 10帧 = 333ms@30fps
  eyeMinFluctuation: 0.008,
  mouthMinFluctuation: 0.005,
  activityThreshold: 0.2
}

// Web 应用（平衡）
const webConfig = {
  frameBufferSize: 15,           // 15帧 = 500ms@30fps
  eyeMinFluctuation: 0.008,
  mouthMinFluctuation: 0.005,
  activityThreshold: 0.2
}

// 金融应用（高安全性）
const financeConfig = {
  frameBufferSize: 20,           // 20帧 = 667ms@30fps
  eyeMinFluctuation: 0.006,      // 更敏感
  mouthMinFluctuation: 0.004,
  activityThreshold: 0.15        // 更严格
}
```

### 2. 防护等级对比

| 防护等级 | 帧数需求 | 检测方法 | 防护强度 | 场景 |
|--------|---------|--------|--------|------|
| **初级** | 5-8 帧 | 眼睛/嘴巴 + 刚性运动 | ⭐⭐ | 内部应用 |
| **中级** | 10-15 帧 | + 单应性 + 透视 | ⭐⭐⭐⭐ | 普通应用 |
| **高级** | 15-20 帧 | + 深度检测 + 交叉比率 | ⭐⭐⭐⭐⭐ | 金融级 |
| **最高** | 20+ 帧 | + 多模型融合 + 人工审核 | ⭐⭐⭐⭐⭐ | 司法级 |

### 3. 用户体验优化

```typescript
// 实时反馈（帮助用户配合）
if (!detector.isReady()) {
  const progress = (frameCount / 5) * 100;
  showProgressBar(progress);
  // "请稍候，正在检测...40%"
}

// 完成后快速响应
if (detector.isReady()) {
  const result = detector.analyzeMotion(...);
  if (result.isLively) {
    showSuccess("检测通过");
  } else {
    showError(result.getMessage());
  }
}
```

### 4. 不同硬件的适配

```typescript
// 高端设备（GPU 加速）
if (device.isHighEnd) {
  frameBufferSize = 20;  // 可承受更多帧处理
  enableAllDetections = true;
  processingInterval = 30;  // ms
}

// 中端设备
if (device.isMidRange) {
  frameBufferSize = 15;
  disableExpensiveAlgorithms = false;
  processingInterval = 50;
}

// 低端设备
if (device.isLowEnd) {
  frameBufferSize = 10;
  disableExpensiveAlgorithms = true;  // 禁用单应性、透视等
  processingInterval = 100;
}
```

### 5. 综合防护策略

```typescript
/**
 * 推荐的两阶段防护策略
 */

// 第一阶段：快速筛选（5-8 帧）
// 成本低，速度快，拒绝明显的照片
{
  frameBufferSize: 8
  enablePhotoDetection: true   // 刚性运动、基本几何
  enableBioFeatureDetection: true  // 眨眼、张嘴
}

// 通过第一阶段 → 进入第二阶段

// 第二阶段：深度检测（额外 8-12 帧）
// 成本高，但更安全，检测高质量照片
{
  enableAdvancedGeometry: true  // 单应性、交叉比率
  enableDepthAnalysis: true     // Z 坐标分析
  totalFrames: 15-20
}

// 最终结果 = 两阶段综合判定
```

---

## 总结

### 核心结论

1. **最少需要 5 帧**才能开始活体检测（167ms@30fps）
2. **推荐使用 10-15 帧**获得良好的准确率和响应速度
3. **高安全应用需要 15-20+ 帧**以启用所有防护机制

### 检测算法分类

| 分类 | 算法 | 防护强度 | 帧数需求 |
|-----|------|--------|---------|
| **正向** | 眼睛/嘴巴波动 | ⭐⭐ | 3-5 帧 |
| **正向** | 肌肉微动 | ⭐⭐⭐ | 2-5 帧 |
| **逆向** | 刚性运动 | ⭐⭐⭐ | 2-5 帧 |
| **逆向** | 单应性约束 | ⭐⭐⭐⭐⭐ | 2+ 帧 |
| **逆向** | 透视变换 | ⭐⭐⭐⭐ | 3-5 帧 |
| **逆向** | 交叉比率 | ⭐⭐⭐⭐ | 2+ 帧 |
| **逆向** | 深度分析 | ⭐⭐⭐ | 3-5 帧 |

### 选择建议

- **用户认证应用**：10-15 帧，正向 + 基本逆向检测
- **支付场景**：15 帧，启用所有检测
- **司法应用**：20+ 帧 + 人工审核
