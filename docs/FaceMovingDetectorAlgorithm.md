# 人脸运动检测算法文档

## 概述

人脸运动检测器是一个基于 MediaPipe Face Mesh 的轻量级运动检测机制，旨在通过分析连续帧间人脸关键点的几何变化，检测由头部姿态调整、表情变化或外部移动引起的形变信号。

## 核心原理

该算法的核心思想是通过分析连续帧之间人脸关键点的几何变化来检测运动。主要步骤包括：

1. **关键点获取**：提取归一化的人脸关键点坐标（x, y ∈ [0,1]），共468个点
2. **平移不变性处理**：以鼻尖关键点（索引为1）为原点进行中心化
3. **帧间位移计算**：计算当前帧与前一帧的欧氏距离平均值
4. **运动判定**：若位移超过阈值，判定为运动状态

## 主要功能

### 1. 运动强度指标
- 当前帧的运动强度 (0-1)
- 历史帧的平均运动强度
- 运动强度的标准差
- 历史帧中的最大/最小运动强度

### 2. 运动状态指标
- 是否检测到有效运动
- 运动检测置信度 (0-1)
- 连续运动帧数
- 运动持续时长（秒）

### 3. 中心化坐标偏移
- 最后一帧的中心化关键点偏移（相对于鼻尖）
- 中心化坐标的变化速率

## 算法流程

### 关键点中心化
为了消除人脸整体平移的干扰，算法以鼻尖（索引为 nosePointIndex）为原点将所有关键点的坐标转换为相对坐标：

```
p' = p - p_nose
```

其中，`p'` 是中心化后的坐标，`p` 是原始坐标，`p_nose` 是鼻尖坐标。

### 帧间位移计算
算法计算两帧之间的运动强度：
1. 对两帧的关键点进行中心化处理
2. 计算对应关键点之间的欧氏距离
3. 取所有距离的平均值作为运动强度

### 运动强度归一化
将位移归一化到 [0, 1] 范围，假设最大合理位移为 0.1（相对于图像尺寸），超过此值仍记为 1.0。

```
normalizedMovement = min(1, averageDisplacement / 0.1)
```

### 运动状态判定
1. 判断当前帧的运动强度是否超过预设阈值
2. 如果超过阈值，则增加连续运动帧计数
3. 如果未超过阈值，则将连续运动帧计数清零
4. 当连续运动帧数达到最小连续帧数要求时，判定为有效运动

## 配置参数

| 参数 | 默认值 | 说明 |
|------|--------|------|
| frameBufferSize | 30 | 缓冲帧数，用于计算时序特征 |
| movementThreshold | 0.015 | 运动阈值，超过此值判定为运动 |
| minContinuousFrames | 1 | 最小连续运动帧数，用于降噪 |
| nosePointIndex | 1 | 鼻尖关键点索引（用于中心化） |

## 算法特点

1. **抗平移性**：通过以鼻尖为原点进行中心化处理，消除了人脸整体平移的影响
2. **实时性**：采用滑动窗口机制，只保留最近的固定帧数，保证了实时性能
3. **抗噪声**：通过连续帧数要求，降低了偶然抖动造成的误判
4. **可量化**：提供多种量化指标，便于分析和调试

## 使用场景

此算法适用于以下场景：
- 人脸识别前的活体检测
- 防止静态照片攻击
- 验证用户是否在主动配合认证过程
- 监控摄像头画面中的人脸活动情况

## 性能指标

- 时间复杂度：O(n)，其中 n 是关键点数量（468）
- 空间复杂度：O(m)，其中 m 是缓冲区大小
- 实时性：支持 30fps 视频流的实时处理