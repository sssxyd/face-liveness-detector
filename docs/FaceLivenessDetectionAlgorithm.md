FaceLivenessDetectionAlgorithm.md
# 活体人脸检测算法文档

## 概述

本活体检测系统采用**三阶段检测方案**，通过人脸运动检测、照片攻击检测和动作检测相结合的方式，有效防范照片、视频等欺骗攻击。系统要求每帧图像中必有人脸且人脸占比足够大，通过分析人脸关键点的几何变化来判断是否为活体。

## 核心原理

系统采用分阶段检测策略：

1. **第一阶段**：人脸运动检测，确认用户是否进行了有效的头部运动
2. **第二阶段**：照片攻击检测，分析运动的几何特征，区分真实人脸和照片
3. **第三阶段**：动作检测，随机选择动作让被检测者执行，进一步防范视频回放攻击

只有当前一阶段检测通过后，才会进行下一阶段检测。

## 环境要求

### 视频帧质量要求

1. **每帧图片中必有人脸**：系统依赖于连续的人脸检测结果，若某一帧无人脸，则中断检测
2. **每帧图片中的人脸都占比不小**：人脸需占据画面的一定比例（建议不少于画面的40%），以确保关键点检测精度
3. **光照条件良好**：避免强烈背光或过暗环境，确保人脸细节清晰可见

### 技术要求

- **检测框架**：基于 MediaPipe Face Mesh 的 468 个人脸关键点
- **坐标系统**：归一化坐标 (x, y ∈ [0, 1])
- **帧率要求**：建议 ≥ 15 fps，以确保有足够的运动信息进行分析

## 三阶段检测流程

### 第一阶段：人脸运动检测

#### 功能定位
检测用户是否进行了有效的头部运动，迫使攻击者无法只用静止照片通过检测。

#### 核心算法
- **中心化处理**：以鼻尖（索引为1）为原点进行中心化，消除人脸整体平移的干扰
- **帧间运动强度计算**：计算相邻帧间所有关键点的平均欧氏距离
- **运动状态判定**：当运动强度超过阈值且连续帧数达标时，判定为有效运动

#### 关键参数
- `frameBufferSize`: 30帧（约1秒@30fps）
- `movementThreshold`: 0.015（运动强度阈值）
- `minContinuousFrames`: 1（最小连续运动帧数）

#### 判定逻辑
- 若检测到有效运动（`isMoving = true`），进入第二阶段
- 若未检测到有效运动（`isMoving = false`），直接判定为非活体，不进行第二阶段检测

### 第二阶段：照片攻击检测

#### 功能定位
在确认用户有运动的基础上，通过分析运动的几何特征，区分真实人脸和照片。

#### 核心算法
基于透视一致性假设：
- **真实人脸**：由于透视效应，近处点（如鼻尖）的移动幅度大于远处点（如耳朵）
- **照片攻击**：所有点按照同一仿射变换移动，各点运动向量高度一致

#### 四大检测指标
1. **运动位移方差**：真实人脸方差大（>0.005），照片方差小（<0.005）
2. **透视比率**：真实人脸比率>1，照片比率≈1
3. **运动方向一致性**：真实人一致性低（<0.8），照片一致性高（>0.8）
4. **仿射变换匹配度**：真实人匹配度低，照片匹配度高

#### 关键参数
- `frameBufferSize`: 15帧（约0.5秒@30fps）
- `motionVarianceThreshold`: 0.005
- `perspectiveRatioThreshold`: 1.08（经验值）
- `motionConsistencyThreshold`: 0.8

### 第三阶段：动作检测

#### 功能定位
通过随机指定动作让用户执行，进一步验证是否为真人，有效防范视频回放攻击。

#### 核心算法
- **随机动作选择**：从预设动作列表中随机选择一个动作指令
- **实时动作识别**：利用 Human.js 的 gesture 模块检测用户是否执行了正确的动作
- **动作匹配验证**：对比用户执行的动作与指令要求是否一致

#### 支持的动作类型
1. **眨眼**（BLINK）：检测眼部关键点变化，识别眨眼动作
2. **张嘴**（MOUTH_OPEN）：检测嘴部关键点间距，识别张嘴动作
3. **点头向下**（NOD_DOWN）：检测头部俯仰角度变化，识别点头动作
4. **抬头向上**（NOD_UP）：检测头部俯仰角度变化，识别抬头动作

#### 关键参数
- `action_liveness_action_randomize`: 是否随机选择动作
- `action_liveness_verify_timeout`: 单个动作验证超时时间
- `action_liveness_action_count`: 需要执行的动作总数
- `action_liveness_min_mouth_open_percent`: 张嘴动作的最小开口百分比

#### 判定逻辑
- **动作开始**：发送动作指令给用户
- **动作检测**：持续监测用户是否执行了指定动作
- **动作匹配**：验证执行的动作与指令是否一致
- **超时控制**：若在规定时间内未完成动作，则判定为失败

## 联合判定逻辑

```
输入视频流
    ↓
[环境检查] - 每帧是否有人脸？人脸是否足够大？
    ↓
[第一阶段] 人脸运动检测
    ↓
是否检测到有效运动？
    ↓ 是
[第二阶段] 照片攻击检测
    ↓
是否通过照片检测？
    ↓ 是
[第三阶段] 动作检测
    ↓
输出活体判定结果
```

### 详细判定流程

1. **环境检查**：验证每帧图像中人脸存在且占比足够
2. **运动检测**：若`isMoving = false`，直接返回"非活体"
3. **照片检测**：若通过运动检测，执行照片攻击检测
4. **动作检测**：若通过照片检测，执行动作检测
5. **最终判定**：结合三阶段结果输出最终判断

## 算法协同优势

### 分阶段设计的好处
- **效率提升**：静止照片在第一阶段即被拦截，无需进行复杂的几何分析
- **鲁棒性增强**：多阶段验证，大幅降低误判率
- **适应性好**：能够应对多种攻击场景

### 针对不同攻击类型的防护

#### 静止照片攻击
- **第一阶段拦截**：无运动 → `isMoving = false` → 直接判定为非活体

#### 移动照片攻击（攻击者手持照片移动）
- **第一阶段通过**：检测到整体移动 → `isMoving = true`
- **第二阶段拦截**：所有点运动一致 → 照片特征明显 → `isPhoto = true`

#### 视频回放攻击
- **第一阶段通过**：检测到屏幕内容运动 → `isMoving = true`
- **第二阶段通过**：视频中的人脸运动可能符合透视规律
- **第三阶段拦截**：无法按要求执行随机指定的动作 → `actionCompleted = false`

#### 真实人脸
- **第一阶段通过**：自然头部运动 → `isMoving = true`
- **第二阶段通过**：具备真实3D几何特征 → `isPhoto = false`
- **第三阶段通过**：可以按要求执行随机动作 → `actionCompleted = true` → 判定为活体

## 性能指标

### 时间复杂度
- **总体**：O(n×m)，其中n为关键点数量(468)，m为帧数
- **第一阶段**：O(n)，单帧处理
- **第二阶段**：O(n×k)，k为分析帧数(15帧)
- **第三阶段**：O(1)，动作匹配处理

### 准确率预期
- **真实人脸检出率**：> 95%
- **各类攻击拒绝率**：> 98%

### 内存占用
- **缓冲区**：三阶段总计约45帧数据
- **关键点存储**：468点×坐标×帧数
- **总体估算**：< 500KB

## 参数调优建议

### 针对不同场景的调整
- **宽松模式**：降低阈值，提高通过率，适用于安全要求较低场景
- **严格模式**：提高阈值，降低误判率，适用于高安全要求场景
- **平衡模式**：默认参数，平衡安全性和用户体验
