/**
 * äººè„¸å›¾åƒè´¨é‡æ£€æµ‹æ¨¡å— (ç»Ÿä¸€ç‰ˆ)
 * 
 * ç»¼åˆæ£€æµ‹äººè„¸å›¾åƒçš„ï¼š
 * 1. å®Œæ•´åº¦æ£€æµ‹ - äººè„¸æ˜¯å¦å®Œæ•´åœ¨æ¡†å†…
 * 2. æ¨¡ç³Šåº¦æ£€æµ‹ - å›¾åƒæ˜¯å¦æ¸…æ™°
 * 3. è½®å»“æ¸…æ™°åº¦ - è½®å»“çš„è¿é€šæ€§å’Œå®Œæ•´åº¦
 * 
 * ä½¿ç”¨æ··åˆæ£€æµ‹ç­–ç•¥ï¼Œç»“åˆ Human.js å’Œ OpenCV.js ä¼˜åŠ¿
 */

import { Box } from '@vladmandic/human'
import { ImageQualityFeatures } from './types'

// ==================== å¸¸é‡é…ç½® ====================

/**
 * è´¨é‡æ£€æµ‹çš„æƒé‡é…ç½®
 * å¯æ ¹æ®éœ€è¦è°ƒæ•´ä»¥æ”¹å˜å„ç»´åº¦çš„é‡è¦æ€§
 */
const QUALITY_WEIGHTS = {
  completeness: 0.4,      // äººè„¸å®Œæ•´åº¦æƒé‡
  sharpness: 0.6,         // æ¸…æ™°åº¦æƒé‡
  human_detection: 0.8,   // Human.jsæ£€æµ‹æƒé‡
  opencv_enhancement: 0.2, // OpenCVå¢å¼ºæƒé‡
  laplacian: 0.6,         // æ‹‰æ™®æ‹‰æ–¯æ–¹å·®æƒé‡
  gradient: 0.4           // æ¢¯åº¦æ¸…æ™°åº¦æƒé‡
} as const

/**
 * OpenCVå›¾åƒå¤„ç†å‚æ•°
 */
const OPENCV_PARAMS = {
  canny_threshold_low: 50,
  canny_threshold_high: 150,
  sobel_kernel_size: 3,
  sobel_type: 'CV_64F',
  laplacian_type: 'CV_64F',
  gradient_energy_scale: 100,
  laplacian_variance_scale: 150,
  edge_ratio_reference: 0.3,
  edge_ratio_low: 0.05,
  edge_ratio_high: 0.7
} as const

// ==================== æ¥å£å®šä¹‰ ====================

/**
 * å•ä¸ªæ£€æµ‹æŒ‡æ ‡çš„ç»“æœ
 */
export interface QualityMetricResult {
  name: string           // æŒ‡æ ‡åç§°
  value: number         // å®é™…å€¼
  threshold: number     // é˜ˆå€¼
  passed: boolean       // æ˜¯å¦é€šè¿‡
  description: string   // æè¿°
}

/**
 * å›¾åƒè´¨é‡æ£€æµ‹çš„ç»¼åˆç»“æœ
 */
export interface ImageQualityResult {
  // æ€»ä½“æ˜¯å¦é€šè¿‡
  passed: boolean
  // ç»¼åˆè´¨é‡è¯„åˆ† (0-1)
  score: number
  // å„ç±»å‹ä¸é€šè¿‡çš„åŸå› åˆ—è¡¨
  completenessReasons: string[]
  blurReasons: string[]
  // å„ä¸ªç»´åº¦çš„è¯¦ç»†æŒ‡æ ‡
  metrics: {
    completeness: QualityMetricResult
    laplacianVariance: QualityMetricResult
    gradientSharpness: QualityMetricResult
    overallQuality: QualityMetricResult
  }
  // å»ºè®®
  suggestions?: string[]
}

// ==================== ä¸»å…¥å£å‡½æ•° ====================

/**
 * è®¡ç®—å›¾åƒè´¨é‡ï¼ˆå®Œæ•´åº¦ + æ¸…æ™°åº¦ï¼‰
 * 
 * ç»¼åˆæ£€æµ‹ï¼š
 * - äººè„¸å®Œæ•´åº¦ï¼ˆHuman.jsè¾¹ç•Œ + OpenCVè½®å»“ï¼‰
 * - å›¾åƒæ¸…æ™°åº¦ï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·® + Sobelæ¢¯åº¦ï¼‰
 * 
 * @param cv - OpenCV.js å¯¹è±¡ï¼Œç”¨äºæ‰§è¡Œå›¾åƒå¤„ç†æ“ä½œ
 * @param matImage - OpenCV Mat å¯¹è±¡ï¼ŒåŒ…å«ç°åº¦å›¾åƒæ•°æ®
 * @param faceBox - äººè„¸è¾¹ç•Œæ¡† [x, y, width, height]
 * @param imageWidth - å›¾ç‰‡å®½åº¦ï¼ˆåƒç´ ï¼‰ï¼Œç”¨äºè¾¹ç•Œæ£€æŸ¥å’Œå®Œæ•´åº¦è®¡ç®—
 * @param imageHeight - å›¾ç‰‡é«˜åº¦ï¼ˆåƒç´ ï¼‰ï¼Œç”¨äºè¾¹ç•Œæ£€æŸ¥å’Œå®Œæ•´åº¦è®¡ç®—
 * @param config - æ£€æµ‹é…ç½®å¯¹è±¡ï¼ŒåŒ…å«ï¼š
 *   - require_full_face_in_bounds: æ˜¯å¦è¦æ±‚äººè„¸å®Œå…¨åœ¨è¾¹ç•Œå†…
 *   - use_opencv_enhancement: æ˜¯å¦ä½¿ç”¨ OpenCV å¢å¼ºæ£€æµ‹
 *   - min_laplacian_variance: æ‹‰æ™®æ‹‰æ–¯æ–¹å·®æœ€å°é˜ˆå€¼
 *   - min_gradient_sharpness: æ¢¯åº¦æ¸…æ™°åº¦æœ€å°é˜ˆå€¼
 * @param threshold - ç»¼åˆè´¨é‡è¯„åˆ†é˜ˆå€¼ (0-1)ï¼Œå¤§äºç­‰äºæ­¤å€¼åˆ¤å®šä¸ºé€šè¿‡
 * @returns ç»¼åˆè´¨é‡æ£€æµ‹ç»“æœï¼ŒåŒ…å«ï¼š
 *   - passed: æ˜¯å¦é€šè¿‡è´¨é‡æ£€æµ‹
 *   - score: ç»¼åˆè´¨é‡è¯„åˆ† (0-1)
 *   - completenessReasons: å®Œæ•´åº¦ä¸é€šè¿‡åŸå› åˆ—è¡¨
 *   - blurReasons: æ¸…æ™°åº¦ä¸é€šè¿‡åŸå› åˆ—è¡¨
 *   - metrics: å„ç»´åº¦è¯¦ç»†æŒ‡æ ‡ï¼ˆå®Œæ•´åº¦ã€æ‹‰æ™®æ‹‰æ–¯æ–¹å·®ã€æ¢¯åº¦æ¸…æ™°åº¦ã€ç»¼åˆè´¨é‡ï¼‰
 *   - suggestions: æ”¹è¿›å»ºè®®åˆ—è¡¨
 */
export function calcImageQuality(
  cv: any,
  grayFrame: any,
  faceBox: Box,
  imageWidth: number,
  imageHeight: number,
  config: ImageQualityFeatures,
  threshold: number
): ImageQualityResult {
  const metrics: Record<string, QualityMetricResult> = {}
  const completenessReasons: string[] = []
  const blurReasons: string[] = []

  // ===== å‰ç½®æ­¥éª¤ï¼šæå–äººè„¸ROIåŒºåŸŸï¼Œé¿å…é‡å¤ROIæ“ä½œ =====
  let faceBoundROI: any = null
  const roiParams = validateAndCalculateROI(faceBox[0], faceBox[1], faceBox[2], faceBox[3], grayFrame)
  
  if (!roiParams.valid) {
    // äººè„¸åŒºåŸŸæ— æ•ˆï¼Œè¿”å›å¤±è´¥ç»“æœ
    return {
      passed: false,
      score: 0,
      completenessReasons: ['äººè„¸åŒºåŸŸæ— æ•ˆæˆ–è¶…å‡ºå›¾åƒè¾¹ç•Œ'],
      blurReasons: [],
      metrics: {
        completeness: {
          name: 'äººè„¸å®Œæ•´åº¦',
          value: 0,
          threshold: 0.8,
          passed: false,
          description: 'äººè„¸åŒºåŸŸæ— æ•ˆæˆ–è¶…å‡ºå›¾åƒè¾¹ç•Œ'
        },
        laplacianVariance: {
          name: 'æ‹‰æ™®æ‹‰æ–¯æ–¹å·®',
          value: 0,
          threshold: config.min_laplacian_variance,
          passed: false,
          description: 'äººè„¸åŒºåŸŸæ— æ•ˆï¼Œæ— æ³•è¿›è¡Œæ¸…æ™°åº¦æ£€æµ‹'
        },
        gradientSharpness: {
          name: 'æ¢¯åº¦æ¸…æ™°åº¦',
          value: 0,
          threshold: config.min_gradient_sharpness,
          passed: false,
          description: 'äººè„¸åŒºåŸŸæ— æ•ˆï¼Œæ— æ³•è¿›è¡Œæ¸…æ™°åº¦æ£€æµ‹'
        },
        overallQuality: {
          name: 'ç»¼åˆå›¾åƒè´¨é‡',
          value: 0,
          threshold: threshold,
          passed: false,
          description: 'äººè„¸åŒºåŸŸæ— æ•ˆï¼Œæ— æ³•è¿›è¡Œè´¨é‡æ£€æµ‹'
        }
      }
    }
  }

  try {
    faceBoundROI = grayFrame.roi(new cv.Rect(roiParams.x, roiParams.y, roiParams.width, roiParams.height))

    // ===== ç¬¬ä¸€éƒ¨åˆ†ï¼šå®Œæ•´åº¦æ£€æµ‹ =====
    const completenessResult = checkFaceCompletenessInternal(
      cv,
      faceBoundROI,
      faceBox,
      roiParams.width,
      roiParams.height,
      config
    )
    metrics.completeness = completenessResult as any
    if (!completenessResult.passed) {
      completenessReasons.push(completenessResult.description)
    }

    // ===== ç¬¬äºŒéƒ¨åˆ†ï¼šæ¸…æ™°åº¦æ£€æµ‹ =====
    const blurResult = checkImageSharpness(cv, faceBoundROI, config)
    metrics.laplacianVariance = blurResult.laplacianVariance
    metrics.gradientSharpness = blurResult.gradientSharpness
    if (!blurResult.laplacianVariance.passed) {
      blurReasons.push(blurResult.laplacianVariance.description)
    }
    if (!blurResult.gradientSharpness.passed) {
      blurReasons.push(blurResult.gradientSharpness.description)
    }

    // ===== ç¬¬ä¸‰éƒ¨åˆ†ï¼šç»¼åˆè¯„åˆ† =====
    // åŠ æƒï¼šå®Œæ•´åº¦ + æ¸…æ™°åº¦ï¼ˆä½¿ç”¨å¯é…ç½®æƒé‡ï¼‰
    const completenessScore = Math.min(1, completenessResult.value)
    const sharpnessScore = blurResult.overallScore
    const overallScore = 
      completenessScore * QUALITY_WEIGHTS.completeness + 
      sharpnessScore * QUALITY_WEIGHTS.sharpness

    const overallMetric: QualityMetricResult = {
      name: 'ç»¼åˆå›¾åƒè´¨é‡',
      value: overallScore,
      threshold: threshold,
      passed: overallScore >= threshold,
      description: `ç»¼åˆè´¨é‡è¯„åˆ† ${(overallScore * 100).toFixed(1)}% (å®Œæ•´åº¦: ${(completenessScore * 100).toFixed(0)}% | æ¸…æ™°åº¦: ${(sharpnessScore * 100).toFixed(0)}%)`
    }
    metrics.overallQuality = overallMetric

    const passed = overallScore >= threshold

    const suggestions: string[] = []
    if (!completenessResult.passed) {
      if (completenessResult.value < 0.5) {
        suggestions.push('è¯·è°ƒæ•´æ‘„åƒå¤´è§’åº¦æˆ–ä½ç½®ï¼Œç¡®ä¿æ•´ä¸ªäººè„¸éƒ½åœ¨ç”»é¢å†…')
      }
    }
    if (!blurResult.laplacianVariance.passed) {
      suggestions.push('å›¾åƒè¾¹ç¼˜ä¸æ¸…æ™°ï¼Œè¯·ç¡®ä¿å…‰çº¿å……è¶³ä¸”æ‘„åƒå¤´å¯¹ç„¦æ¸…æ¥š')
    }
    if (!blurResult.gradientSharpness.passed) {
      suggestions.push('å›¾åƒçº¹ç†æ¨¡ç³Šï¼Œå¯èƒ½æ˜¯è¿åŠ¨æ¨¡ç³Šï¼Œè¯·ä¿æŒæ‘„åƒå¤´ç¨³å®š')
    }

    return {
      passed,
      score: overallScore,
      completenessReasons,
      blurReasons,
      metrics: metrics as any,
      suggestions: suggestions.length > 0 ? suggestions : undefined
    }
  } catch (error) {
    console.error('[ImageQuality] calcImageQuality failed:', error)
    return {
      passed: false,
      score: 0,
      completenessReasons: [`è´¨é‡æ£€æµ‹å¼‚å¸¸: ${error instanceof Error ? error.message : String(error)}`],
      blurReasons: [],
      metrics: {
        completeness: {
          name: 'äººè„¸å®Œæ•´åº¦',
          value: 0,
          threshold: 0.8,
          passed: false,
          description: 'æ£€æµ‹å¼‚å¸¸'
        },
        laplacianVariance: {
          name: 'æ‹‰æ™®æ‹‰æ–¯æ–¹å·®',
          value: 0,
          threshold: config.min_laplacian_variance,
          passed: false,
          description: 'æ£€æµ‹å¼‚å¸¸'
        },
        gradientSharpness: {
          name: 'æ¢¯åº¦æ¸…æ™°åº¦',
          value: 0,
          threshold: config.min_gradient_sharpness,
          passed: false,
          description: 'æ£€æµ‹å¼‚å¸¸'
        },
        overallQuality: {
          name: 'ç»¼åˆå›¾åƒè´¨é‡',
          value: 0,
          threshold: threshold,
          passed: false,
          description: 'æ£€æµ‹å¼‚å¸¸'
        }
      }
    }
  } finally {
    if (faceBoundROI && faceBoundROI !== grayFrame) {
      try {
        faceBoundROI.delete()
      } catch (e) {
        // å¿½ç•¥åˆ é™¤é”™è¯¯
      }
    }
  }
}

// ==================== å®Œæ•´åº¦æ£€æµ‹ ====================

/**
 * å®Œæ•´åº¦æ£€æµ‹ - å†…éƒ¨å‡½æ•°
 * 
 * æ³¨æ„ï¼šgrayFrame å·²ç»æ˜¯ROIåçš„äººè„¸åŒºåŸŸï¼Œç›´æ¥ä½¿ç”¨å³å¯
 */
function checkFaceCompletenessInternal(
  cv: any,
  grayFrame: any,
  faceBox: Box,
  faceBoxWidth: number,
  faceBoxHeight: number,
  config: ImageQualityFeatures
): QualityMetricResult {
  // ç¬¬ä¸€å±‚ï¼šHuman.js è¾¹ç•Œæ£€æµ‹ (80%)
  // æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯ROIåçš„åæ ‡ï¼Œéœ€è¦ç›¸å¯¹ä½ç½®è®¡ç®—
  let humanScore = calculateHumanCompleteness(faceBox, faceBoxWidth, faceBoxHeight, config.require_full_face_in_bounds)

  // ç¬¬äºŒã€ä¸‰å±‚ï¼šOpenCV å¢å¼ºæ£€æµ‹
  let opencvContourScore = 1.0
  let opencvSharpnessScore = 1.0

  try {
    opencvContourScore = detectFaceCompletenessOpenCVContour(cv, grayFrame)
    opencvSharpnessScore = detectFaceCompletenessOpenCVSharpness(cv, grayFrame)
  } catch (error) {
    console.warn('[ImageQuality] OpenCV enhancement failed:', error)
  }

  // ç»„åˆè¯„åˆ†ï¼šå‡å°‘å¯¹ OpenCV è¾…åŠ©æ£€æµ‹çš„ä¾èµ–
  // Human.js ä½œä¸ºä¸»è¦åˆ¤æ®ï¼ˆæƒé‡æå‡åˆ° 80%ï¼‰ï¼ŒOpenCV ä½œä¸ºè¾…åŠ©å¢å¼ºï¼ˆ20%ï¼‰
  const completenessScore =
    humanScore * QUALITY_WEIGHTS.human_detection +
    Math.max(opencvContourScore, opencvSharpnessScore) * QUALITY_WEIGHTS.opencv_enhancement

  return {
    name: 'äººè„¸å®Œæ•´åº¦',
    value: completenessScore,
    threshold: config.require_full_face_in_bounds ? 1.0 : 0.8,
    passed: completenessScore >= (config.require_full_face_in_bounds ? 1.0 : 0.8),
    description: `äººè„¸å®Œæ•´åº¦ ${(completenessScore * 100).toFixed(1)}% (Human: ${(humanScore * 100).toFixed(0)}% | Contour: ${(opencvContourScore * 100).toFixed(0)}% | Sharpness: ${(opencvSharpnessScore * 100).toFixed(0)}%)`
  }
}

/**
 * Human.js è¾¹ç•Œæ£€æµ‹
 */
function calculateHumanCompleteness(
  faceBox: Box,
  imageWidth: number,
  imageHeight: number,
  requireFullFaceInBounds: boolean
): number {
  if (!faceBox || faceBox.length < 4) {
    return 0
  }

  const [x, y, width, height] = faceBox

  // è®¡ç®—äººè„¸æ¡†åœ¨å›¾ç‰‡å†…çš„æ¯”ä¾‹
  const overlapX = Math.min(Math.max(x + width, 0), imageWidth) - Math.max(x, 0)
  const overlapY = Math.min(Math.max(y + height, 0), imageHeight) - Math.max(y, 0)
  const faceArea = width * height
  const overlapArea = Math.max(0, overlapX) * Math.max(0, overlapY)
  let completenessScore = faceArea > 0 ? overlapArea / faceArea : 0

  if (requireFullFaceInBounds) {
    const isFullyInBounds = x >= 0 && y >= 0 && x + width <= imageWidth && y + height <= imageHeight
    if (!isFullyInBounds) {
      // æ”¹è¿›ï¼šä¸æ˜¯ç›´æ¥è¿”å› 0ï¼Œè€Œæ˜¯æŒ‰è¶…å‡ºç¨‹åº¦æ‰£åˆ†
      // 90% ä»¥ä¸Šåœ¨è¾¹ç•Œå†…å¯ä»¥æ¥å—
      const minCompleteness = 0.9
      if (completenessScore < minCompleteness) {
        completenessScore = completenessScore * 0.5 // è¶…å‡ºè¾ƒå¤šæ—¶ä¸¥é‡æ‰£åˆ†
      }
    }
  }

  return completenessScore
}

/**
 * OpenCV è½®å»“æ£€æµ‹
 * 
 * æ³¨æ„ï¼šgrayFrame å·²ç»æ˜¯ROIåçš„äººè„¸åŒºåŸŸï¼Œç›´æ¥å¤„ç†
 */
function detectFaceCompletenessOpenCVContour(
  cv: any,
  grayFrame: any
): number {
  let edges: any = null
  try {
    edges = new cv.Mat()
    cv.Canny(grayFrame, edges, OPENCV_PARAMS.canny_threshold_low, OPENCV_PARAMS.canny_threshold_high)

    const nonZeroCount = cv.countNonZero(edges)
    const totalPixels = grayFrame.rows * grayFrame.cols

    const edgeRatio = nonZeroCount / totalPixels
    let completenessScore = calculateEdgeQualityScore(edgeRatio)

    return completenessScore
  } catch (error) {
    console.warn('[ImageQuality] OpenCV contour detection failed:', error)
    return 1.0
  } finally {
    if (edges) edges.delete()
  }
}

/**
 * OpenCV è¾¹ç•Œæ¸…æ™°åº¦æ£€æµ‹
 * 
 * æ³¨æ„ï¼šgrayFrame å·²ç»æ˜¯ROIåçš„äººè„¸åŒºåŸŸï¼Œç›´æ¥å¤„ç†
 */
function detectFaceCompletenessOpenCVSharpness(
  cv: any,
  grayFrame: any
): number {
  if (!grayFrame || grayFrame.empty?.()) {
    return 0
  }

  let sobelX: any = null
  let sobelY: any = null
  let gradient: any = null

  try {
    sobelX = new cv.Mat()
    sobelY = new cv.Mat()
    cv.Sobel(grayFrame, sobelX, cv.CV_32F, 1, 0, 3)
    cv.Sobel(grayFrame, sobelY, cv.CV_32F, 0, 1, 3)

    gradient = new cv.Mat()
    cv.magnitude(sobelX, sobelY, gradient)

    const mean = cv.mean(gradient)
    const meanValue = mean[0]

    const sharpnessScore = Math.min(1, meanValue / 100)

    return sharpnessScore
  } catch (error) {
    console.warn('[ImageQuality] OpenCV sharpness detection failed:', error)
    return 1.0
  } finally {
    if (sobelX) sobelX.delete()
    if (sobelY) sobelY.delete()
    if (gradient) gradient.delete()
  }
}

// ==================== æ¸…æ™°åº¦æ£€æµ‹ ====================

/**
 * æ£€æµ‹å›¾åƒæ¸…æ™°åº¦ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰
 * 
 * ä½¿ç”¨æ··åˆç®—æ³•ï¼š
 * 1. æ‹‰æ™®æ‹‰æ–¯æ–¹å·® (Laplacian Variance) - 60%
 * 2. Sobel æ¢¯åº¦æ¸…æ™°åº¦ - 40%
 * 
 * æ³¨æ„ï¼šgrayFrame å·²ç»æ˜¯ROIåçš„äººè„¸åŒºåŸŸï¼Œç›´æ¥ä½¿ç”¨
 */
function checkImageSharpness(
  cv: any,
  grayFrame: any,
  config: ImageQualityFeatures
): {
  laplacianVariance: QualityMetricResult
  gradientSharpness: QualityMetricResult
  overallScore: number
} {
  // ğŸ“Š è¾“å…¥è¯Šæ–­ä¿¡æ¯
  console.log('[ImageQuality] checkImageSharpness input:', {
    matImageValid: !!grayFrame && !grayFrame.empty?.(),
    matImageSize: grayFrame?.cols && grayFrame?.rows ? `${grayFrame.cols}x${grayFrame.rows}` : 'unknown',
    matImageChannels: grayFrame?.channels?.() || 'unknown',
    matImageType: grayFrame?.type?.() || 'unknown'
  })

  try {
    // æ–¹æ³• 1ï¼šæ‹‰æ™®æ‹‰æ–¯æ–¹å·®
    const laplacianResult = calculateLaplacianVariance(cv, grayFrame, config.min_laplacian_variance)

    // æ–¹æ³• 2ï¼šæ¢¯åº¦æ¸…æ™°åº¦
    const gradientResult = calculateGradientSharpness(cv, grayFrame, config.min_gradient_sharpness)

    // ç»¼åˆè¯„åˆ†
    const laplacianScore = Math.min(1, laplacianResult.value / OPENCV_PARAMS.laplacian_variance_scale)
    const gradientScore = gradientResult.value
    const overallScore = 
      QUALITY_WEIGHTS.laplacian * laplacianScore + 
      QUALITY_WEIGHTS.gradient * gradientScore

    return {
      laplacianVariance: laplacianResult,
      gradientSharpness: gradientResult,
      overallScore: Math.min(1, overallScore)
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error('[ImageQuality] Sharpness check error:', errorMsg)
    return {
      laplacianVariance: {
        name: 'æ‹‰æ™®æ‹‰æ–¯æ–¹å·®',
        value: 0,
        threshold: config.min_laplacian_variance,
        passed: false,
        description: `æ£€æµ‹å¤±è´¥: ${errorMsg}`
      },
      gradientSharpness: {
        name: 'æ¢¯åº¦æ¸…æ™°åº¦',
        value: 0,
        threshold: config.min_gradient_sharpness,
        passed: false,
        description: `æ£€æµ‹å¤±è´¥: ${errorMsg}`
      },
      overallScore: 0
    }
  }
}

/**
 * è®¡ç®—æ‹‰æ™®æ‹‰æ–¯æ–¹å·®
 */
function calculateLaplacianVariance(
  cv: any,
  roi: any,
  minThreshold: number
): QualityMetricResult {
  try {
    if (!cv) {
      return {
        name: 'æ‹‰æ™®æ‹‰æ–¯æ–¹å·®',
        value: 1,
        threshold: minThreshold,
        passed: true,
        description: 'OpenCV ä¸å¯ç”¨'
      }
    }

    // è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥ ROI æœ‰æ•ˆæ€§
    const roiIsEmpty = roi.empty ? roi.empty() : (roi.empty?.() ?? true)
    if (!roi || roiIsEmpty) {
      console.warn('[ImageQuality] ROI is empty or invalid for Laplacian calculation', {
        roiNull: !roi,
        roiEmpty: roiIsEmpty,
        roiSize: roi?.cols && roi?.rows ? `${roi.cols}x${roi.rows}` : 'unknown'
      })
      return {
        name: 'æ‹‰æ™®æ‹‰æ–¯æ–¹å·®',
        value: 0,
        threshold: minThreshold,
        passed: false,
        description: 'ROI æ— æ•ˆ'
      }
    }

    let gray = roi
    const needsConversion = roi.channels && roi.channels() !== 1
    if (needsConversion) {
      gray = new cv.Mat()
      cv.cvtColor(roi, gray, cv.COLOR_RGBA2GRAY)
    }

    try {
      const laplacian = new cv.Mat()
      cv.Laplacian(gray, laplacian, cv.CV_64F)

      const mean = new cv.Mat()
      const stddev = new cv.Mat()
      cv.meanStdDev(laplacian, mean, stddev)

      const variance = stddev.doubleAt(0, 0) ** 2

      // è°ƒè¯•ä¿¡æ¯
      if (variance === 0) {
        console.warn('[ImageQuality] Laplacian variance is 0', {
          roiSize: roi.size ? `${roi.cols}x${roi.rows}` : 'unknown',
          roiChannels: roi.channels ? roi.channels() : 'unknown',
          laplacianEmpty: laplacian.empty?.(),
          stddevValue: stddev.doubleAt(0, 0)
        })
      }

      laplacian.delete()
      mean.delete()
      stddev.delete()

      const passed = variance >= minThreshold

      return {
        name: 'æ‹‰æ™®æ‹‰æ–¯æ–¹å·®',
        value: variance,
        threshold: minThreshold,
        passed,
        description: `æ‹‰æ™®æ‹‰æ–¯æ–¹å·® ${variance.toFixed(1)} ${passed ? 'âœ“' : 'âœ— éœ€ â‰¥' + minThreshold}`
      }
    } finally {
      if (gray !== roi && needsConversion) {
        gray.delete()
      }
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error('[ImageQuality] Laplacian calculation error:', errorMsg, {
      roiValid: roi && !roi.empty?.(),
      roiSize: roi?.cols && roi?.rows ? `${roi.cols}x${roi.rows}` : 'unknown'
    })
    return {
      name: 'æ‹‰æ™®æ‹‰æ–¯æ–¹å·®',
      value: 0,
      threshold: minThreshold,
      passed: false,
      description: `è®¡ç®—å¤±è´¥: ${errorMsg}`
    }
  }
}

/**
 * è®¡ç®— Sobel æ¢¯åº¦æ¸…æ™°åº¦
 */
function calculateGradientSharpness(
  cv: any,
  roi: any,
  minThreshold: number
): QualityMetricResult {
  try {
    if (!cv) {
      return {
        name: 'æ¢¯åº¦æ¸…æ™°åº¦',
        value: 1,
        threshold: minThreshold,
        passed: true,
        description: 'OpenCV ä¸å¯ç”¨'
      }
    }

    // è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥ ROI æœ‰æ•ˆæ€§
    const roiIsEmpty = roi.empty ? roi.empty() : (roi.empty?.() ?? true)
    if (!roi || roiIsEmpty) {
      console.warn('[ImageQuality] ROI is empty or invalid for Sobel calculation', {
        roiNull: !roi,
        roiEmpty: roiIsEmpty,
        roiSize: roi?.cols && roi?.rows ? `${roi.cols}x${roi.rows}` : 'unknown'
      })
      return {
        name: 'æ¢¯åº¦æ¸…æ™°åº¦',
        value: 0,
        threshold: minThreshold,
        passed: false,
        description: 'ROI æ— æ•ˆ'
      }
    }

    let gray = roi
    const needsConversion = roi.channels && roi.channels() !== 1
    if (needsConversion) {
      gray = new cv.Mat()
      cv.cvtColor(roi, gray, cv.COLOR_RGBA2GRAY)
    }

    let gradX: any = null
    let gradY: any = null
    let gradMagnitude: any = null

    try {
      gradX = new cv.Mat()
      gradY = new cv.Mat()

      cv.Sobel(gray, gradX, cv[OPENCV_PARAMS.sobel_type], 1, 0, OPENCV_PARAMS.sobel_kernel_size)
      cv.Sobel(gray, gradY, cv[OPENCV_PARAMS.sobel_type], 0, 1, OPENCV_PARAMS.sobel_kernel_size)

      gradMagnitude = new cv.Mat()
      cv.magnitude(gradX, gradY, gradMagnitude)

      const mean = cv.mean(gradMagnitude)
      const gradientEnergy = mean[0]

      const sharpnessScore = Math.min(1, gradientEnergy / OPENCV_PARAMS.gradient_energy_scale)

      // è°ƒè¯•ä¿¡æ¯
      if (sharpnessScore === 0) {
        console.warn('[ImageQuality] Gradient sharpness is 0', {
          roiSize: roi.size ? `${roi.cols}x${roi.rows}` : 'unknown',
          gradientEnergy: gradientEnergy,
          gradMagnitudeEmpty: gradMagnitude.empty?.(),
          meanValue: mean
        })
      }

      const passed = sharpnessScore >= minThreshold

      return {
        name: 'æ¢¯åº¦æ¸…æ™°åº¦',
        value: sharpnessScore,
        threshold: minThreshold,
        passed,
        description: `æ¢¯åº¦æ¸…æ™°åº¦ ${(sharpnessScore * 100).toFixed(1)}% ${passed ? 'âœ“' : 'âœ— éœ€ â‰¥' + (minThreshold * 100).toFixed(0) + '%'}`
      }
    } finally {
      if (gradX) gradX.delete()
      if (gradY) gradY.delete()
      if (gradMagnitude) gradMagnitude.delete()
      if (gray !== roi && needsConversion) {
        gray.delete()
      }
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error('[ImageQuality] Gradient calculation error:', errorMsg, {
      roiValid: roi && !roi.empty?.(),
      roiSize: roi?.cols && roi?.rows ? `${roi.cols}x${roi.rows}` : 'unknown'
    })
    return {
      name: 'æ¢¯åº¦æ¸…æ™°åº¦',
      value: 0,
      threshold: minThreshold,
      passed: false,
      description: `è®¡ç®—å¤±è´¥: ${errorMsg}`
    }
  }
}

// ==================== è¾…åŠ©å‡½æ•° ====================

/**
 * éªŒè¯å¹¶è®¡ç®—æœ‰æ•ˆçš„ROIåŒºåŸŸ
 * 
 * æå–å¹¶éªŒè¯æ„Ÿå…´è¶£åŒºåŸŸ(ROI)çš„æœ‰æ•ˆæ€§ï¼Œç¡®ä¿åæ ‡åœ¨å›¾åƒè¾¹ç•Œå†…
 * 
 * @param x - äººè„¸æ¡†å·¦ä¸Šè§’Xåæ ‡
 * @param y - äººè„¸æ¡†å·¦ä¸Šè§’Yåæ ‡
 * @param w - äººè„¸æ¡†å®½åº¦
 * @param h - äººè„¸æ¡†é«˜åº¦
 * @param image - OpenCV Matå›¾åƒå¯¹è±¡
 * @returns ROIå‚æ•°å’Œæœ‰æ•ˆæ€§æ ‡è®° { valid, x, y, width, height }
 */
function validateAndCalculateROI(
  x: number,
  y: number,
  w: number,
  h: number,
  image: any
): { valid: boolean; x: number; y: number; width: number; height: number } {
  const x_int = Math.max(0, Math.floor(x))
  const y_int = Math.max(0, Math.floor(y))
  const w_int = Math.min(w, image.cols - x_int)
  const h_int = Math.min(h, image.rows - y_int)

  const isValid = w_int > 0 && h_int > 0

  return {
    valid: isValid,
    x: x_int,
    y: y_int,
    width: w_int,
    height: h_int
  }
}

/**
 * è®¡ç®—è¾¹ç¼˜è´¨é‡è¯„åˆ†
 * 
 * æ ¹æ®è¾¹ç¼˜åƒç´ å æ¯”è®¡ç®—è´¨é‡åˆ†æ•°ï¼Œé¿å…è¿‡å¤šæˆ–è¿‡å°‘çš„è¾¹ç¼˜
 * 
 * @param edgeRatio - è¾¹ç¼˜åƒç´ æ¯”ä¾‹ (0-1)
 * @returns è´¨é‡è¯„åˆ† (0-1)
 */
function calculateEdgeQualityScore(edgeRatio: number): number {
  const { edge_ratio_reference, edge_ratio_low, edge_ratio_high } = OPENCV_PARAMS

  if (edgeRatio < edge_ratio_low) {
    // è¾¹ç¼˜è¿‡å°‘ï¼šè´¨é‡å·®
    return 0
  } else if (edgeRatio > edge_ratio_high) {
    // è¾¹ç¼˜è¿‡å¤šï¼šå¯èƒ½æœ‰å™ªå£°ï¼Œè´¨é‡ä¸‹é™
    return Math.max(0.3, 1 - (edgeRatio - 0.3) / 2)
  } else {
    // æ­£å¸¸èŒƒå›´ï¼šçº¿æ€§è¯„åˆ†
    return Math.min(1, edgeRatio / edge_ratio_reference)
  }
}